{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "from time import time  # To time our operations\n",
    "import multiprocessing\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JesterPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JesterPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of cores in a computer\n",
    "cores = multiprocessing.cpu_count()\n",
    "t = time()\n",
    "\n",
    "with open(\"data/data_origin.DUMP\", encoding=\"utf8\") as tsv:\n",
    "    counter = 0\n",
    "\n",
    "    sentences = []\n",
    "    for line in csv.reader(tsv, dialect=\"excel-tab\"):\n",
    "        # counter += 1\n",
    "        sentence = line[2]\n",
    "\n",
    "        # trim punctuation\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "        cleared_words = []\n",
    "        # print(sentence)\n",
    "\n",
    "        all_words = nltk.word_tokenize(sentence)\n",
    "        # print(all_words)\n",
    "\n",
    "        for word in all_words:\n",
    "            if word not in stopwords.words('turkish'):\n",
    "                cleared_words.append(word)\n",
    "\n",
    "        sentences.append(cleared_words)\n",
    "\n",
    "        # if counter == 50:\n",
    "        #     break\n",
    "        \n",
    "print('Time to tokenize: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(cleared_words)\n",
    "w2v_model = Word2Vec(min_count=2,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=cores - 1)\n",
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=100)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=10, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)\n",
    "\n",
    "w2v_model.wv.save_word2vec_format('models/model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('models/model.bin', binary=True)\n",
    "print(model.wv['ngc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
