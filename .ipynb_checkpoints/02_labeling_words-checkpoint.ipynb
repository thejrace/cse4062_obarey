{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "\"\"\"\n",
    "Part 2: \n",
    "    Objective: \n",
    "    \n",
    "    Step 1: Read labeled tokens and group them by defined categories.\n",
    "\n",
    "        Input:\n",
    "            |     Token       |    Category   |\n",
    "            |-----------------|---------------|\n",
    "            |  B-person_name  |     Person    |\n",
    "            |-----------------|---------------|\n",
    "            | B-location_name |    Location   |\n",
    "            |-----------------|---------------|\n",
    "            |   B-film_actor  |    Person     |\n",
    "\n",
    "\n",
    "    Output:\n",
    "    \n",
    "        Objective: This list will be used for calculating centroid for categories\n",
    "        entity_categories = {\n",
    "            'Person'   : { 'person_name', 'film_actor' },\n",
    "            'Location' : { 'location_name' }\n",
    "        }\n",
    "        \n",
    "        Objective: This list will be used for labeling words faster. \n",
    "        Brief    : The reason for this list is that when we're labeling\n",
    "        words, in order to find label we have to 'find' it in entity_categories. With this list in hand we can\n",
    "        find the category without looping through entity_categories.\n",
    "        entity_category_dictionary = {\n",
    "            'person_name' : 'Person',\n",
    "            'location_name' : 'Location',        \n",
    "        }\n",
    "        \n",
    "        \n",
    "    Step 2: Read dataset and label words with their corresponding categories.\n",
    "        \n",
    "        Labeling action:\n",
    "            \n",
    "            Corina        |  B-politician_name     ----|  Person\n",
    "\t        Casanova      |  I-politician_name     ----|\n",
    "\t        ,             |  O\n",
    "\t        İsviçre       |  B-person_nationality  ----| Nationality\n",
    "\t        Federal       |  O\n",
    "\t        Şansölyesidir |  B-governmental_jurisdiction_basic_title  | PersonType\n",
    "\t        .             |  O\n",
    "\n",
    "        Output:\n",
    "            labeled_words = {\n",
    "                'Corina Casanova': 'Person',\n",
    "                'İsviçre': 'Nationality',\n",
    "                'Şansölyesidir' : 'PersonType',\n",
    "                ..\n",
    "            }\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### Helpers ####\n",
    " \n",
    "# Removes token identifiers from string.\n",
    "def remove_token_identifiers(raw_token):\n",
    "    return raw_token.replace('B-', '').replace('I-', '')\n",
    "\n",
    "# Checks whether token is inner.\n",
    "def is_inner_token(raw_token):\n",
    "    return raw_token.find('I-') != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### STEP 1 ####\n",
    "\n",
    "t = time()\n",
    "my_printer = pprint.PrettyPrinter()\n",
    "\n",
    "# Read file\n",
    "df = pd.read_excel('data/labeled_categories.xlsx')\n",
    "\n",
    "# Fallback category for the tokens does not belong to chosen categories\n",
    "fallback_category = 'Thing'\n",
    "# Main category list\n",
    "category_list = [\n",
    "    'Person', 'Location', 'Event', 'Organization', 'DateTime', 'PersonType', 'Currency', 'Nationality', 'Ethnicity'\n",
    "]\n",
    "# Initialize category-entity dictionary\n",
    "entity_categories = {fallback_category : set({})}\n",
    "entity_category_dictionary = {}\n",
    "\n",
    "for category in category_list:\n",
    "    entity_categories[category] = set({})\n",
    "\n",
    "# Read Excel file and fill the dictionary\n",
    "for row in df.index:\n",
    "    token = remove_token_identifiers(df['Token'][row])\n",
    "    token = token[:token.find(' =')]\n",
    "    category = df['Category'][row]\n",
    "    \n",
    "    # Fallback category check\n",
    "    if category == '' or category == 'Delete' or category == 'delete' or category == 'Thing' or category == 'thing':\n",
    "        entity_categories[fallback_category].add(token)\n",
    "        entity_category_dictionary[token] = fallback_category\n",
    "        continue\n",
    "    \n",
    "    # Undefined category check\n",
    "    if category not in category_list:\n",
    "        continue\n",
    "    \n",
    "    # Valid category\n",
    "    entity_categories[category].add(token)\n",
    "    entity_category_dictionary[token] = category\n",
    "                \n",
    "print('Time to create entity categories: {} mins'.format(round((time() - t) / 60, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# my_printer.pprint(entity_categories)\n",
    "print(entity_category_dictionary['person_name'])\n",
    "# my_printer.pprint(entity_categories['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " #### STEP 2 ####\n",
    "\n",
    "t = time()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Read dataset\n",
    "with open(\"data/data_origin.DUMP\", encoding=\"utf8\") as tsv:\n",
    "    \n",
    "    labeled_words = []\n",
    "\n",
    "    \n",
    "    for line in csv.reader(tsv, dialect=\"excel-tab\"):\n",
    "        tokenized = line[1]\n",
    "        sentence = line[2]\n",
    "        \n",
    "        all_words = nltk.word_tokenize(sentence)\n",
    "        all_tokens = nltk.word_tokenize(tokenized)\n",
    "        \n",
    "        sentence_valid_tokens = []\n",
    "        \n",
    "        for x in range(len(all_words)):\n",
    "            try:\n",
    "                token_raw = all_tokens[x]\n",
    "                \n",
    "                if token_raw == 'O':\n",
    "                    continue\n",
    "                \n",
    "                token = remove_token_identifiers(token_raw)\n",
    "                    \n",
    "                if token not in entity_category_dictionary:\n",
    "                    continue\n",
    "                \n",
    "                label = entity_category_dictionary[token]\n",
    "                \n",
    "                word = all_words[x]\n",
    "                   \n",
    "                if word in labeled_words:\n",
    "                    continue\n",
    "                    \n",
    "                df = df.append({\n",
    "                    'Word': word,\n",
    "                    'Label': label,\n",
    "                }, ignore_index=True)\n",
    "                \n",
    "                labeled_words.append(word)\n",
    "                \n",
    "                # print(word + ' : ' + label)\n",
    "            \n",
    "            except IndexError:\n",
    "                pass\n",
    "            \n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print('Time to label the entities: {} mins'.format(round((time() - t) / 60, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(4))\n",
    "t = time()\n",
    "\n",
    "writer = pd.ExcelWriter('data/labeled_words_single.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "print('Time to save: {} mins'.format(round((time() - t) / 60, 4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
